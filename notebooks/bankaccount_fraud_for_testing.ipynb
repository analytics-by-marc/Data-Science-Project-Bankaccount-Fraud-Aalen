{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7826f0e0-9fcf-4e60-8a9c-a3d24477720b",
   "metadata": {},
   "source": [
    "## Lade Pakete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a09a696-cf18-488b-b927-5086cb40b91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # um Pfad anzulegen oder zu ändern\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "import lightgbm as lgb\n",
    "\n",
    "#sklearn Pakete\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import train_test_split, HalvingRandomSearchCV, GridSearchCV, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, PolynomialFeatures, LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, average_precision_score, recall_score, precision_score, precision_recall_curve, f1_score, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, mutual_info_classif\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import SimpleImputer # ersetzen von fehlenden Werten\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from scipy.stats import ttest_ind\n",
    "from lightgbm import LGBMClassifier\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE # Oversampling\n",
    "from imblearn.under_sampling import RandomUnderSampler # Undersampling\n",
    "from imblearn.pipeline import Pipeline # spezielle Pipeline für SMOTE nötig\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# statsmodel Pakete\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0cca37-0519-444e-a199-3ab1ff13720a",
   "metadata": {},
   "source": [
    "## Pfadeingabe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c27ea27-fc0f-4b2f-ac36-fe9ca67cd6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pfad zum lokalen Speicherort der Daten, r davor einfügen damit spezielle Zeichen auch als String erkannt werden\n",
    "data_dir = r\"C:\\Users\\MLA6FE\\Desktop\\Data_Science_Project\\data\"\n",
    "file_path = os.path.join(data_dir, \"bankaccounts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf40c2f-e0ec-435e-8208-94fd8cdeb378",
   "metadata": {},
   "source": [
    "## CSV-Daten in data frame laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19d4e6c2-f048-43fe-8159-ded14ba0e117",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bankaccounts = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b35f564-b08c-401f-8db9-c779cbe47c51",
   "metadata": {},
   "source": [
    "## Überblick über Daten verschaffen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133f0220-ef7e-42c9-9a64-39eab674ef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_bankaccounts.head() # erste 5 Zeilen des Datensatzes\n",
    "#df.shape               # Anzahl der Zeilen und Spalten\n",
    "#df.columns             # Spaltennamen\n",
    "df_bankaccounts.info()  # Spaltennamen, 0-Werte, Datentypen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325b9f53-d9ad-49fb-a9ad-7954e373ed0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datensatz auf Duplikate überprüfen\n",
    "\n",
    "#df_bankaccounts[df_bankaccounts.duplicated()] # zeigt ganze Zeilen mit den Duplikaten an\n",
    "df_bankaccounts.duplicated().sum() # gibt Summe der doppelten Zeilen an"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5275bf5-b58f-4f5c-89ab-ba89a344cefd",
   "metadata": {},
   "source": [
    "## Nicht benötigte Spalten löschen und unter X (unabhängige Variablen) und y (abhängige Variable) speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db5af89e-7d14-4e10-892d-2071739e6be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000000, 31), (1000000,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_bankaccounts.drop(axis = 1, columns = [\"x1\", \"x2\", \"fraud_bool\"]) # löscht die gewünschten Spalten aus data frame\n",
    "y = df_bankaccounts[\"fraud_bool\"] # erzeugt data frame y mit gewünschter Spalte\n",
    "X.shape, y.shape # gibt die Form der data frames aus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ad9c00-78f4-455e-a160-0ae85882c413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Darstellen aller Daten\n",
    "# Anzahl der Spalten\n",
    "cols = X.columns\n",
    "n_cols = 4  # Spalten pro Reihe\n",
    "n_rows = math.ceil(len(cols) / n_cols)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*5, n_rows*4))\n",
    "axes = axes.flatten()  # 2D-Array in 1D für einfaches Iterieren\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Kategoriale Features\n",
    "    if X[col].dtype == 'object' or X[col].nunique() < 20:\n",
    "        sns.countplot(x=col, data=X, order=X[col].value_counts().index, ax=ax)\n",
    "        ax.set_title(f'{col} (kategorial)')\n",
    "        ax.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "    # Numerische Features\n",
    "    else:\n",
    "        sns.histplot(X[col], bins=20, kde=False, ax=ax)\n",
    "        ax.set_title(f'{col} (numerisch)')\n",
    "\n",
    "# Leere Achsen ausblenden\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbec3a0-bf89-4ae9-8504-8d5723625847",
   "metadata": {},
   "source": [
    "## Häufigkeit der Werte der Zielgröße über alle Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22624556-0144-4396-a537-19e8f6468a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiere style für alle folgenden plots\n",
    "plt.style.use('bmh')\n",
    "\n",
    "fraud_or_not = y.value_counts(normalize=True).sort_index() * 100 # zählt alle Häufigkeiten je Kategortie und sortiert es nach aufsteigendem index\n",
    "# normalisiert die Werte und multipliziert sie mit 100 für eine prozentuale Darstellung\n",
    "\n",
    "# gibt Tabelle aus mit prozentualer Verteilung\n",
    "print(\"Prozentuale Verteilung:\", fraud_or_not)\n",
    "\n",
    "#erstellt barplot\n",
    "fraud_or_not.plot(kind=\"bar\", color=\"skyblue\")\n",
    "plt.ylabel(\"Anteil (%)\")\n",
    "plt.xlabel(\"Betrugsfall oder nicht\")\n",
    "plt.title(\"Betrugsquote\")\n",
    "plt.xticks(rotation=0) # damit Zahlen nicht gedreht werden\n",
    "\n",
    "plt.tight_layout()  # saubere Darstellung\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e6e618-8206-42a9-bcf4-b616c6674522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schleife, welche über alle features des Datensatzes X geht und die prozentuale Darstellung für y 0 und 1 ausgibt\n",
    "for feature in X:\n",
    "    print(f\"\\n Verteilung von y nach {feature}:\")\n",
    "    display(pd.crosstab(X[feature], y, normalize='index') * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49201292-6ebe-4485-87c7-080b6759c43e",
   "metadata": {},
   "source": [
    "## Verteilung der geschützten Attribute in Barplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515dd624-4aff-49b2-b0bd-51ee26f8967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suplots anlegen\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 6))\n",
    "\n",
    "# income\n",
    "X[\"income\"].value_counts().sort_index().plot(kind=\"bar\", color=\"skyblue\", ax=axes[0]) # zählt alle Häufigkeiten je Kategortie und sortiert es nach aufsteigendem index\n",
    "axes[0].set_title(\"Verteilung Einkommen\")\n",
    "axes[0].set_xlabel(\"Einkommenskategorie\")\n",
    "axes[0].set_ylabel(\"Häufigkeit\")\n",
    "\n",
    "#costumer age\n",
    "X[\"customer_age\"].value_counts().sort_index().plot(kind=\"bar\", color=\"lightgreen\", ax=axes[1])\n",
    "axes[1].set_title(\"Verteilung Alter\")\n",
    "axes[1].set_xlabel(\"Alter\")\n",
    "\n",
    "#employment status\n",
    "X[\"employment_status\"].value_counts().sort_index().plot(kind=\"bar\", color=\"purple\", ax=axes[2])\n",
    "axes[2].set_title(\"Verteilung Angestellte\")\n",
    "axes[2].set_xlabel(\"Angestelltenverhältnis\")\n",
    "\n",
    "plt.tight_layout()  # saubere Darstellung\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bf7f44-01f7-417f-9ba8-aea9dc29c40c",
   "metadata": {},
   "source": [
    "## Häufigkeit der Zielgröße bei den geschützten Attributen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860dda5a-9001-42fc-9abe-6c3c132a790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# erstelle crosstabs, Kreuztabellen wie oft jede Kombination mit 0, 1 vorkommt\n",
    "crosstab_income = pd.crosstab(X[\"income\"], y, normalize='index') * 100\n",
    "crosstab_costumer_age = pd.crosstab(X[\"customer_age\"], y, normalize='index') * 100\n",
    "crosstab_employment_status = pd.crosstab(X[\"employment_status\"], y, normalize='index') * 100\n",
    "\n",
    "# Tabelle mit den Prozentwerten ausgeben\n",
    "print(crosstab_income)\n",
    "print(crosstab_costumer_age)\n",
    "print(crosstab_employment_status)\n",
    "\n",
    "# Suplots anlegen\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 6))\n",
    "\n",
    "# income\n",
    "crosstab_income.plot(kind='bar', stacked=True, color=['skyblue', 'salmon'], ax=axes[0])\n",
    "axes[0].set_title(\"fraud_bool beim Einkommen\")\n",
    "axes[0].set_xlabel(\"Einkommenskategorie\")\n",
    "axes[0].set_ylabel(\"Anzahl\")\n",
    "\n",
    "#costumer age\n",
    "crosstab_costumer_age.plot(kind='bar', stacked=True, color=['skyblue', 'salmon'], ax=axes[1])\n",
    "axes[1].set_title(\"fraud_bool beim Alter\")\n",
    "axes[1].set_xlabel(\"Alter\")\n",
    "\n",
    "#employment status\n",
    "crosstab_employment_status.plot(kind='bar', stacked=True, color=['skyblue', 'salmon'], ax=axes[2])\n",
    "axes[2].set_title(\"fraud_bool bei den Angestellten\")\n",
    "axes[2].set_xlabel(\"Angestelltenverhältnis\")\n",
    "\n",
    "plt.tight_layout()  # saubere Darstellung\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489ff0dd-c020-49c3-ab96-c40db9e252a1",
   "metadata": {},
   "source": [
    "## Datensatz nach fehlenden Werten untersuchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482eef73-ecae-4894-9fd7-4d8e795181a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gibt für jede Spalte die Summe der fehlende Werte aus\n",
    "print(X.isna().sum())\n",
    "print(y.isna().sum())\n",
    "# keine 0-Werte enthalten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1185f77d-f89c-4cb7-80a4-940e3ec639ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_address_months_count: 762005\n",
      "current_address_months_count: 3473\n",
      "intended_balcon_amount: 751724\n",
      "bank_months_count: 247242\n",
      "session_length_in_minutes: 2256\n",
      "device_distinct_emails_8w: 332\n"
     ]
    }
   ],
   "source": [
    "# Alle Spalten mit fehlenden Werten manuell erfassen\n",
    "missing_values = [\"prev_address_months_count\", \n",
    "                  \"current_address_months_count\", \n",
    "                  \"bank_months_count\", \n",
    "                  \"session_length_in_minutes\",\n",
    "                  \"session_length_in_minutes\", \n",
    "                  \"device_distinct_emails_8w\",\n",
    "                 \"intended_balcon_amount\"]\n",
    "\n",
    "# iteriert über alle Spalten des DataFrames X\n",
    "for col in X.columns:\n",
    "    if col in missing_values: # schaut nach den Spalten mit missing values\n",
    "        if (X[col] < 0).any(): # schaut nach den Werten dieser Spalten kleiner 0\n",
    "            missing = (X[col] < 0).sum() # gibt die Summe der missing values also kleiner 0 aus\n",
    "            print(f\"{col}: {missing}\") # gibt diese aus\n",
    "            X[col] = X[col].apply(lambda x: np.nan if x < 0 else x) # ersetzt die fehlenden Werte druch np.nan zur besseren Weiterverarbeitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f32892eb-6dce-4030-bb2a-2f2173d3206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(axis = 1, columns = [\"prev_address_months_count\", \"intended_balcon_amount\"]) # Entferne Spalten/Features mit über 50% fehlenden Werten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1de6bb3-77b6-45b8-8799-74892d7629b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fehlende Werte ersetzen (-1 Werte in diesem Fall)\n",
    "# -1 Werte als NaN markieren\n",
    "X['current_address_months_count'] = X['current_address_months_count'].replace(-1, np.nan)\n",
    "X[\"bank_months_count\"] = X[\"bank_months_count\"].replace(-1, np.nan)\n",
    "X[\"session_length_in_minutes\"] = X[\"session_length_in_minutes\"].replace(-1, np.nan)\n",
    "X[\"device_distinct_emails_8w\"] = X[\"device_distinct_emails_8w\"].replace(-1, np.nan)\n",
    "\n",
    "# Mean Imputer erstellen\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Spalten imputen mit Durchschnittswert der jeweiligen Spalte\n",
    "X['current_address_months_count'] = imputer.fit_transform(X[['current_address_months_count']])\n",
    "X[\"bank_months_count\"] = imputer.fit_transform(X[[\"bank_months_count\"]])\n",
    "X[\"session_length_in_minutes\"] = imputer.fit_transform(X[[\"session_length_in_minutes\"]])\n",
    "X[\"device_distinct_emails_8w\"] = imputer.fit_transform(X[[\"device_distinct_emails_8w\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50df1072-901f-4ba3-8d56-8a8ed41a3480",
   "metadata": {},
   "source": [
    "## Kategoriale Spalten durch Dummies ersetzen mit Label Encoding und OneHot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34e32a45-20fa-4197-8848-9b21d4b497ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_dummy_encoding(X, encoder):\n",
    "    \"\"\"\n",
    "    Wendet auf alle object-Spalten entweder LabelEncoding oder OneHotEncoding an.\n",
    "    \n",
    "    Parameter:\n",
    "        X (DataFrame): Eingabedaten\n",
    "        encoder (str): \"label\" oder \"onehot\"\n",
    "    \"\"\"\n",
    "    \n",
    "    X = X.copy()  # Original nicht überschreiben\n",
    "\n",
    "    manuell_encoding = [\"income\", \"customer_age\", \"month\"]\n",
    "    \n",
    "    # Label Encoding - Umwandlung einer Spalte in 0, 1, 2, 3, etc. \n",
    "    if encoder == \"label\":\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        for col in X.columns:\n",
    "            if X[col].dtype == \"object\" or col in manuell_encoding: # encoded alle Spalten vom Datentyp object oder wenn vorhanden manuell definierte Spalten\n",
    "                print(f\"Label-Encoding für: {col}\")\n",
    "                X[col] = le.fit_transform(X[col].astype(str)) # astype(str) wandelt alle Werte in Strings um falls eine Spalte mehrere Typen hat\n",
    "                # fit_transform lernt und transformiert, welche Kategorien es gibt (\"rot\", \"blau\", \"grün\") und wandelt sie in Zahlen um (z. B. 0, 1, 2)\n",
    "    \n",
    "    # OneHot Encoding - Umwandlung einer Spalte in mehrere binäre Spalten 0/1\n",
    "    elif encoder == \"onehot\":\n",
    "        \n",
    "        for col in manuell_encoding: # zuerst manuell zu encodede numerische Spalten encoden, falls vorhanden\n",
    "            if col in X.columns:\n",
    "                print(f\"OneHot-Encoding (manuell) für: {col}\")\n",
    "                dummies = pd.get_dummies(X[col], prefix=col, drop_first=True).astype(int) # prefix = col alle neuen Dummy-Spalten bekommen den Spaltennamen als Präfix, jeder Wert der kategorialen Spalte bekommt eigene neue Spalte\n",
    "                # überlegen ob drop_first = True, um Multikollinearität zu vermeiden...zum Beispiel alle Werte = 1 - bei True entfernt es die erste binäre Spalte\n",
    "                dummies = dummies.astype(int) # durch .astype(int) werden die erzeugten boolschen Werte True und False in 0 und 1 umgewandelt für die bessere Weiterverarveitung\n",
    "                X = X.drop(columns=[col]) # entfernt ursprüngliche zu ersetzende Spalte\n",
    "                X = pd.concat([X, dummies], axis=1) # concat nimmt beide DataFrames und fügt sie spaltenweise zusammen, die dummie-Spalten kommen an das Ende des DtaaFrames\n",
    "        \n",
    "        for col in X.select_dtypes(include=['object']).columns:\n",
    "            print(f\"OneHot-Encoding für: {col}\")\n",
    "            dummies = pd.get_dummies(X[col], prefix=col, drop_first=True) # prefix = col alle neuen Dummy-Spalten bekommen den Spaltennamen als Präfix, jeder Wert der kategorialen Spalte bekommt eigene neue Spalte\n",
    "            # überlegen ob drop_first = True, um Multikollinearität zu vermeiden...zum Beispiel alle Werte = 1 - bei True entfernt es die erste binäre Spalte\n",
    "            dummies = dummies.astype(int) # durch .astype(int) werden die erzeugten boolschen Werte True und False in 0 und 1 umgewandelt für die bessere Weiterverarveitung\n",
    "            X = X.drop(columns=[col]) # entfernt ursprüngliche zu ersetzende Spalte\n",
    "            X = pd.concat([X, dummies], axis=1) # concat nimmt beide DataFrames und fügt sie spaltenweise zusammen, die dummie-Spalten kommen an das Ende des DtaaFrames\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"encoder muss 'label' oder 'onehot' sein.\")\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a44143da-582e-40ae-ae3b-eeaf47541be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHot-Encoding (manuell) für: income\n",
      "OneHot-Encoding (manuell) für: customer_age\n",
      "OneHot-Encoding (manuell) für: month\n",
      "OneHot-Encoding für: payment_type\n",
      "OneHot-Encoding für: employment_status\n",
      "OneHot-Encoding für: housing_status\n",
      "OneHot-Encoding für: source\n",
      "OneHot-Encoding für: device_os\n"
     ]
    }
   ],
   "source": [
    "X = data_dummy_encoding(X, \"onehot\") # Optionen: LabelEncoder() = \"label\" OneHotEncoder() = \"onehot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a725abce-539c-4c87-b703-8fa16de01498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datentypen checken, ob Umwandlung funktioniert hat\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b395da-e5bd-41ca-bc3d-9e77b5c22f2a",
   "metadata": {},
   "source": [
    "## Logistische Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76abe4ad-7553-46b5-b387-3741faf14fa4",
   "metadata": {},
   "source": [
    "Vorgehensweise\n",
    "\n",
    "1. Prüfen, ob Zielvariable binär ist (0 / 1) --> schon erledigt, passt\n",
    "2. Duplikate immer löschen...machen das Modell schlechter!\n",
    "3. Prüfen der Verteilung von y (Zielvariable) --> schon erledigt, Modell stark unausgeglichen mit 0: 98,89 %\n",
    "   Hohe Accuracy bei der Betrachtung nicht alleine ausreichend (Modell könnte immer 0 vorraussagen für eine hohe Accuracy) --> Betrugsfälle werden nicht ausreichend erfasst\n",
    "   Lösung: z. B. LogisticRegression(class_weight = \"balanced\") gewichtet seltene Klasse stärker und häufige Klasse geringer, \n",
    "   Oversampling der Minderheitsklasse durch erzeugen von mehr Beispielen, \n",
    "   Undersampling der Mehrheitsklasse(schlecht, Daten gehen verloren)\n",
    "4. Datentypen der Feature prüfen und kategorische Feature in Dummies (0 / 1) oder mehr Zahlen umwandeln. Bei OneHotEncoding() drop_first = True evtl. sinnvoll um Multikollinearität zu vermeiden...\n",
    "   zum Beispiel alle Werte = 1, entfernt dann die     erste binäre Spalte\n",
    "5. Datensatz nach fehlenden Werten untersuchen und Zeilen/Spalten löschen oder auffüllen mit z. b. Durchschnittswert --> schon erledigt\n",
    "6. Skalierung (nicht immer nötig), bringt alle numerischen Feature auf eine ähnliche Skala, unterschiedliche Skalen verzerren die Gewichtungen.\n",
    "   Bei der lodistischen Regression ist das nicht unbedingt notwendig aber wenn mit Regularisierung (Strafterme) zwingedn erforderlich\n",
    "7. Auf perfekte oder starke Korrelationen prüfen wegen Multikollinearität (Features enthalten fast gleiche Informationen, führt z. B. zu instabiler Gewichtung) --> erst nach Dummieumwandlung, bei kategorialen Features nicht möglich\n",
    "   Korrelation berechnen und darstellen mit z. b. Heatmap\n",
    "   Obere Dreiecksmatrix auswählen...reicht aus, da untere Dreiecksmatrix die gleiche Berechnung macht nur die Features sind auf der x- und y-Achse vertauscht. Spart Rechenzeit\n",
    "   Stark korrelierte Features identifizieren, Schwellenwert setzen welche Feature bei welcher Korrelation entfernt werden sollen, z. B. größer gleich 0,9 für starke Korrelation\n",
    "   Die Feature mit hoher Korrelation entfernen\n",
    "   Nochmal diesen Schritt durchführen, ob es besser geworden ist: Korrelation berechnen und darstellen mit z. b. Heatmap\n",
    "   Skalierung vorher nicht unbedingt nötig\n",
    "   corr (in Python ist damit standardmäßig die Pearson Korrelation gemeint) und VIF geht nur zuverlässig mit linearen Beziehungen zwischen Features!\n",
    "8. Feature auf Varianz untersuchen, misst, die stark sich die Werte eines Merkmals unterscheiden. Ein feature das fast nur die gleichen Werte z. b. immer nur 1 oder 0 hat bringt keine \n",
    "   Informationen für das Modell (bringt mathematische Probleme bei nur 0-Werten und unnötigen Rechenaufwand mit sich)\n",
    "   Manuell prüfen oder mit VarianceThreshold von sklearn (damit werden Spalten mit vorgegebener Varianz aufomatisch entfernt)\n",
    "   0.01 = 1% Varianz, bedeutet es werden alle Spalten entfernt, bei denen eine Klasse 99% vorkommt\n",
    "   Man muss hier auch Unterscheiden, für Dummie Feature nimmt man hier eher höhere Werte als für kontinuierliche Feature mit mehr Werten\n",
    "   Skalierung vorher zwingend nötig, da Varianz stark skalenabhängig\n",
    "9. Prüfen auf Anzahl der Feature und Beobachtungen, Faustregel: Mindestend 10-20 Beobachtungen pro Feature --> locker erfüllt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e471d9a-e75d-4149-9305-965f7b6ca43e",
   "metadata": {},
   "source": [
    "## Skalierung durchführen von bestimmten Spalten, Spalten die sich schon zwischen 0 und 1 bewegen nicht mehr Skalieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5210ead4-f982-4057-84b6-c06c563cc20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alle numerischen Spalten auswählen\n",
    "numerische_Spalten = X.select_dtypes(include=['int', 'float']).columns\n",
    "\n",
    "# Binäre Spalten identifizieren (mit 0 und 1)\n",
    "binäre_Spalten = [col for col in numerische_Spalten if X[col].dropna().isin([0,1]).all()]\n",
    "\n",
    "nicht_skalierte_Spalte = binäre_Spalten\n",
    "\n",
    "print(\"Binäre Spalten:\", binäre_Spalten)\n",
    "\n",
    "skalierte_Spalten = []\n",
    "\n",
    "# Spalten, die skaliert werden sollen durch Schleife auswählen\n",
    "for col in X.columns:\n",
    "    if col in nicht_skalierte_Spalte:\n",
    "        pass\n",
    "    else:\n",
    "        skalierte_Spalten.append(col)\n",
    "\n",
    "# Skalieren\n",
    "scaler = MinMaxScaler()\n",
    "#scaler = RobustScaler()\n",
    "X = X.copy()\n",
    "X[skalierte_Spalten] = scaler.fit_transform(X[skalierte_Spalten])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae2d480-b1e2-4b45-ab31-ba4fc8d3abbb",
   "metadata": {},
   "source": [
    "## Korrelationen berechnen, Multikolinearität vermeiden und Features mit hoher Korrelation löschen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43bb3c7-5ec9-480d-9aaa-7328e1ffa3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korrelation berechnen\n",
    "corr_matrix = X.corr().abs() # abs() sehr wichtig, da auch Negativkorrelationen möglich sind und diese sonst nicht vom Threshold weiter unten erfasst werden\n",
    "\n",
    "# Heatmap zur visuellen Kontrolle\n",
    "plt.figure(figsize=(40, 20))\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm', annot=True, cbar_kws={'label': 'Korrelation'}) # annot = True schreibt Werte in die Kästchen, cbar_kws={'label': 'Korrelation'} labeled die Skala rechts\n",
    "plt.title(\"Korrelationsmatrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff990767-e596-41ee-aa02-84d52de9c4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# untere oder obere Dreiecksmatrix auswählen (in diesem Fall die untere)\n",
    "untere = corr_matrix.where(np.tril(np.ones(corr_matrix.shape), k=-1).astype(bool))\n",
    "\n",
    "# stark korrelierte Features identifizieren\n",
    "threshold = 0.8 # Threshold  für Korrelation wählen...je näher an 1 desto höher\n",
    "to_drop = [column for column in untere.columns if any(untere[column] > threshold)]\n",
    "print(\"Features mit starker Korrelation über threshold:\", to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba722c3-ef15-4fda-9697-78c7cc5abcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features mit hoher Korrelation entfernen\n",
    "\n",
    "X = X.drop(columns=to_drop)\n",
    "print(\"Neue Form des DataFrames:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244a1e0e-8a03-4d27-a5c1-03fb86938509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neue Korrelsationen nochmal prüfen\n",
    "corr_matrix_reduced = X.corr().abs() # abs() sehr wichtig, da auch Negativkorrelationen möglich sind und diese sonst nicht vom Threshold weiter unten erfasst werden\n",
    "\n",
    "# Heatmap zur visuellen Kontrolle\n",
    "plt.figure(figsize=(40, 20))\n",
    "sns.heatmap(corr_matrix_reduced, cmap='coolwarm', annot=True, cbar_kws={'label': 'Korrelation'})\n",
    "plt.title(\"Korrelationsmatrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0792ff7-5416-4b59-8ce6-87d0b21af8a4",
   "metadata": {},
   "source": [
    "## Varianz berechnen und Features mit niedriger Varianz (viele gleiche Werte) entfernen, da kein Einfluss auf Modell und mehr Rechenleistung nötig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291d9710-0fc8-4c3e-875a-e2a697c019c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varianz aller Feature berechnen\n",
    "variances = X.var()\n",
    "\n",
    "# Als Heatmap darstellen\n",
    "plt.figure(figsize=(20, len(X.columns)*0.3))  # Höhe abhängig von Anzahl Features\n",
    "sns.heatmap(variances.to_frame(), annot=True, fmt=\".5f\", cmap=\"coolwarm\", cbar_kws={'label': 'Varianz'}) # annot = True schreibt Werte in die Kästchen, \n",
    "# fmt=\".5f\" zeigt Werte im Heatmap nur bis 5 Dezimalstellen für bessere Lesbarkeit an\n",
    "# cbar_kws={'label': 'Varianz'} labeled die Skala rechts\n",
    "\n",
    "plt.title(\"Heatmap der Feature-Varianzen\")\n",
    "plt.xlabel(\"Varianz\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9011f114-0738-4590-b018-b1e38840be23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatisierte Varianzerkennung mit VarianceThreshold: Entfernt Features, deren Varianz unter einem Schwellwert liegt\n",
    "sel = VarianceThreshold(threshold=0.01)  # Nur filter für die Daten, z. B. 0.01 = 1% Varianz, bedeutet es werden alle Spalten entfernt, bei denen eine Klasse 99% vorkommt\n",
    "sel.fit_transform(X) # berechnet die Varianz jedes Features im data frame, verändert Daten nicht\n",
    "\n",
    "# gibt behaltene Spalten aus\n",
    "kept_columns = X.columns[sel.get_support()]\n",
    "\n",
    "# gibt gelöschte Spalten aus\n",
    "removed_columns = X.columns[~sel.get_support()]\n",
    "\n",
    "#speichert die behaltenen Feature über Threshold in DataFrame\n",
    "X = X[kept_columns]\n",
    "\n",
    "#print(\"Behaltene Spalten (über Threshold):\")\n",
    "#print(list(kept_columns))\n",
    "\n",
    "print(\"\\n Entfernte Spalten (unter Threshold):\")\n",
    "print(list(removed_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fcbfad-1609-49b7-8829-85ec8c38e847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zuerst 10% der Daten ziehen (stratifiziert nach y)\n",
    "X_small, _, y_small, _ = train_test_split(\n",
    "    X, y, train_size=0.1, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Dann normalen Train/Test Split innerhalb der 10%\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_small, y_small,\n",
    "    test_size=0.3,       # 30% Test innerhalb der 10%\n",
    "    stratify=y_small,    # Klassenverteilung bleibt erhalten\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Aufteilen der Daten in Train und Testdaten\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify=y)\n",
    "# stratify=y sorgt dafür, dass die Anteile der Klassen in y im Trainings- und Testset gleich bleiben. 0: 98.897% und 1: 1.103% in train und test-Daten.\n",
    "# Bei stark unbalancierten Daten mit geringer Wahrscheinlichkeit einer Klasse wichtig, ohne stratify=y könnte es zufällig passieren, dass im Testset gar keine oder nur sehr wenige Klasse 1 ennthalten sind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59d5ad9-563e-4983-9298-73418c1221de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufteilen der Daten in Train und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify=y)\n",
    "# stratify=y sorgt dafür, dass die Anteile der Klassen in y im Trainings- und Testset gleich bleiben. 0: 98.897% und 1: 1.103% in train und test-Daten.\n",
    "# Bei stark unbalancierten Daten mit geringer Wahrscheinlichkeit einer Klasse wichtig, ohne stratify=y könnte es zufällig passieren, dass im Testset gar keine oder nur sehr wenige Klasse 1 ennthalten sind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad1b72-fa44-4b6d-aa8b-673abead08db",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "# scale_pos_weight für XGBoost/LightGBM = (#neg)/(#pos) für die beste Gewichtung\n",
    "n_pos = np.sum(y_train == 1)\n",
    "n_neg = np.sum(y_train == 0)\n",
    "scale_pos_weight = n_neg / max(1, n_pos)\n",
    "print(\"scale_pos_weight (neg/pos):\", scale_pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffc6218-3f07-4f95-8999-6a9a3853b324",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(y_train)\n",
    "cls_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weight_dict = {c: w for c, w in zip(classes, cls_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dceafd-6b59-4c31-b6cc-30d5ed03de0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "# CV und Scoring\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "scoring = \"average_precision\"  # primär; z. B. \"roc_auc\" oder \"precision\" möglich\n",
    "\n",
    "# Modelle + Grids (Pipeline nur mit Klassifier)\n",
    "models_and_grids = {\n",
    "    \"DecisionTree\": {\n",
    "        \"estimator\": Pipeline([\n",
    "            (\"clf\", DecisionTreeClassifier(random_state=RANDOM_STATE))\n",
    "        ]),\n",
    "        \"param_grid\": {\n",
    "            \"clf__criterion\": [\"gini\", \"entropy\"],\n",
    "            \"clf__max_depth\": [5, 10, 20, None],\n",
    "            \"clf__min_samples_leaf\": [1, 5, 20],\n",
    "            \"clf__class_weight\": [None, \"balanced\", class_weight_dict]\n",
    "        }\n",
    "    },\n",
    "    #\"RandomForest\": {\n",
    "        #\"estimator\": Pipeline([\n",
    "         #   (\"clf\", RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1))\n",
    "        #]),\n",
    "        #\"param_grid\": {\n",
    "         #   \"clf__n_estimators\": [100, 300],\n",
    "          #  \"clf__max_depth\": [10, 20, None],\n",
    "           # \"clf__min_samples_leaf\": [1, 5, 10],\n",
    "            #\"clf__class_weight\": [None, \"balanced\", \"balanced_subsample\"]\n",
    "        #}\n",
    "    #},\n",
    "    \"GradientBoosting\": {\n",
    "        \"estimator\": Pipeline([\n",
    "            (\"clf\", GradientBoostingClassifier(random_state=RANDOM_STATE))\n",
    "        ]),\n",
    "        \"param_grid\": {\n",
    "            \"clf__n_estimators\": [100, 300],\n",
    "            \"clf__learning_rate\": [0.05, 0.1],\n",
    "            \"clf__max_depth\": [3, 6],\n",
    "            \"clf__min_samples_leaf\": [1, 5]\n",
    "        }\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"estimator\": Pipeline([\n",
    "            (\"clf\", xgb.XGBClassifier(\n",
    "                random_state=RANDOM_STATE,\n",
    "                use_label_encoder=False,\n",
    "                eval_metric=\"logloss\",\n",
    "                n_jobs=-1\n",
    "            ))\n",
    "        ]),\n",
    "        \"param_grid\": {\n",
    "            \"clf__n_estimators\": [100, 300],\n",
    "            \"clf__max_depth\": [3, 6],\n",
    "            \"clf__learning_rate\": [0.05, 0.1],\n",
    "            \"clf__scale_pos_weight\": [scale_pos_weight, 1.0]\n",
    "        }\n",
    "    },\n",
    "    \"LightGBM\": {\n",
    "        \"estimator\": Pipeline([\n",
    "            (\"clf\", LGBMClassifier(random_state=RANDOM_STATE, n_jobs=-1))\n",
    "        ]),\n",
    "        \"param_grid\": {\n",
    "            \"clf__n_estimators\": [100, 300],\n",
    "            \"clf__num_leaves\": [31, 64],\n",
    "            \"clf__max_depth\": [-1, 10, 20],\n",
    "            \"clf__learning_rate\": [0.05, 0.1],\n",
    "            \"clf__scale_pos_weight\": [scale_pos_weight, 1.0]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Funktion für GridSearch + Evaluation\n",
    "def run_grid_and_eval(name, estimator, param_grid, X_train, y_train, X_test, y_test):\n",
    "    print(\"\\n\\n==========\", name, \"==========\")\n",
    "    model_search = GridSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_grid=param_grid,\n",
    "        scoring=scoring,\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "        refit=True\n",
    "    )\n",
    "    model_search.fit(X_train, y_train)\n",
    "    print(\"Best Params:\", model_search.best_params_)\n",
    "    print(\"Best CV ({}): {:.4f}\".format(scoring, model_search.best_score_))\n",
    "    \n",
    "    best = model_search.best_estimator_\n",
    "    y_pred = best.predict(X_test)\n",
    "    y_proba = None\n",
    "    if hasattr(best, \"predict_proba\"):\n",
    "        y_proba = best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(f\"TN={tn}, FP={fp}, FN={fn}, TP={tp}\")\n",
    "\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    rocauc = roc_auc_score(y_test, y_proba) if y_proba is not None else None\n",
    "\n",
    "    print(\"\\nPrecision (pos): {:.4f}\".format(precision))\n",
    "    print(\"Recall (pos): {:.4f}\".format(recall))\n",
    "    print(\"F1 (pos): {:.4f}\".format(f1))\n",
    "    if rocauc is not None:\n",
    "        print(\"ROC-AUC: {:.4f}\".format(rocauc))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=4, zero_division=0))\n",
    "    \n",
    "    return model_search, {\"precision\": precision, \"recall\": recall, \"f1\": f1, \"roc_auc\": rocauc, \"cm\": cm}\n",
    "\n",
    "# Alles ausführen\n",
    "results = {}\n",
    "for name, cfg in models_and_grids.items():\n",
    "    gs, metrics = run_grid_and_eval(name, cfg[\"estimator\"], cfg[\"param_grid\"], X_train, y_train, X_test, y_test)\n",
    "    results[name] = {\"gridsearch\": gs, \"metrics\": metrics}\n",
    "\n",
    "# Kurz-Zusammenfassung\n",
    "summary = {name: { \"f1\": results[name][\"metrics\"][\"f1\"],\n",
    "                   \"precision\": results[name][\"metrics\"][\"precision\"],\n",
    "                   \"recall\": results[name][\"metrics\"][\"recall\"],\n",
    "                   \"roc_auc\": results[name][\"metrics\"][\"roc_auc\"] } \n",
    "           for name in results}\n",
    "\n",
    "print(\"\\n\\n=== Kurz Übersicht (Test) ===\")\n",
    "for k, v in summary.items():\n",
    "    print(f\"{k:12} -> F1: {v['f1']:.4f}, Precision: {v['precision']:.4f}, Recall: {v['recall']:.4f}, ROC-AUC: {v['roc_auc']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23aa79f-a524-451e-bc0c-dfbd75d0d408",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Vorbereitung der Daten mit Pipeline, eine Pipeline kann für sehr viele Modelle genutzt werden und arbeitet die verschiedenen Schritte ab\n",
    "\n",
    "#rus = RandomUnderSampler(sampling_strategy='minority', random_state=42)\n",
    "\n",
    "pipe_log = Pipeline([\n",
    "    #(\"undersample\", rus),\n",
    "    #(\"smote\", None), # noch besser als SMOTE für unser Problem, erzeugt synthetische Samples die nahe an der KlassenGrenze liegen. WIrd automatisch nur auf Minderheitsklasse angewandt\n",
    "    #(\"smote\", SMOTE(random_state=42)), # vor dem Model aufrufen, Oversamping, erzeugt neue Datenpunke der Minderheitsklasse nur k-Neighbours, sodass gleich viele Daten von 0 und 1 vorhanden sind\n",
    "    # immer nur nach dem split nur auf Trainiingsdaten, WIrd automatisch nur auf Minderheitsklasse angewandt, danach gleiche Größe wie Mehrheitsklasse\n",
    "    # Benötigt zusätzlichen learn.pipeline import Pipeline für spezielle SMOTE pipeline\n",
    "    # Bestimmung der Funktion, ob Polynome Features eingeführt werden sollen (eher für kleine Datensätze)\n",
    "    #('preprocessing', PolynomialFeatures(2)), \n",
    "    # Bestimmung des Modells, penalty = \"l2\" ist standard und steht für Ridge-Regularisierung\n",
    "    # die Regularisierung führt einen Strafterm ein mit lambda, sodass es zu keinen Übergewichtungen von parametern kommt\n",
    "    # C (=1/lambda) bestimmt die Gesichtung des Strafterms, default ist hier 1.0\n",
    "    # max_iter bestimmt wie viele Iterationen zur Optimierung des Modells durchgeführt werden\n",
    "    #(\"scaler\", MinMaxScaler()),\n",
    "    (\"model\", None)\n",
    "    ])\n",
    "\n",
    "grid_search = {\n",
    "    \"model\": [xgb.XGBClassifier()],\n",
    "    \"model__n_estimators\": [100], # Anzahl der Bäume\n",
    "    \"model__max_depth\": [3], # maximale Tiefe eines Baumes\n",
    "    \"model__scale_pos_weight\": [scale_pos_weight], # Gewichtung der Minderheitsklasse, typisch Anzahl Negativwerte/Anzahl Positivwerte (98,897/1,103 = 89,67 in diesem Fall)\n",
    "    #\"model__reg_lambda\": [1] # Regularisation wie bei Ridge, Strafterm\n",
    "    #\"model__eval_metric\": [\"logloss\"]\n",
    "}\n",
    "\n",
    "# l1 für Lasso: Setzt manche Feature direkt auf 0 und entfernt sie somit, automatische Feature Selektion, starke Feature bleiben, schwache werden gelöscht\n",
    "# l2 für Ridge: Strafterm für Koeffizienten, große Koeffizienten werden mehr bestraft, alle Koeffizienten werden kleiner, keiner wird exakt 0, starke Features bleiben, schwache werden reduziert\n",
    "\n",
    "#erhält im Gegensatz zu kFold die die Klassenverteilung in jedem Fold, also proportional wie im gesamten Datensatz.(also wie bei stratify=y, nur für alle 5 cvs)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "model_grid = GridSearchCV(\n",
    "    pipe_log,\n",
    "    grid_search,\n",
    "    cv = cv, # macht 5 cross validation splits\n",
    "    scoring = \"average_precision\"\n",
    ")\n",
    "\n",
    "# scoring\n",
    "\n",
    "#0    98.897\n",
    "#1     1.103\n",
    "\n",
    "#ROC Kurve\n",
    "\n",
    "# Fit der Daten mit den Traindaten\n",
    "#pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5ead46-bfaa-4531-b59d-2eca28d4c21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6aab42-1455-4c0d-9189-4612b7dc78b9",
   "metadata": {},
   "source": [
    "Wie sollte man das Modell validieren?\n",
    "sehr ungleich verteilte Daten mit \n",
    "\n",
    "fraud_bool\n",
    "0    98.897\n",
    "1     1.103\n",
    "\n",
    "Zahlentechnische Bewertung des Modells\n",
    "1. Precision: Von allen Fällen, die das Modell als „positiv“ vorhergesagt hat, wie viele waren wirklich positiv? Benötigt dazu 0/1 Werte der Minderheitsklasse.\n",
    "2. Recall: Von allen echten positiven Fällen – wie viele erkennt das Modell? Benötigt dazu 0/1 Werte der Minderheitsklasse.\n",
    "3. Average Precision: Wie gut ist mein Modell über alle Thresholds hinweg in Bezug auf Precision & Recall? Benötigt dazu Wahrscheinlichkeiten Werte der Minderheitsklasse.\n",
    "4. ROC-AUC-Score: Die ROC-AUC misst, wie gut der Klassifikator zwischen Positiv und Negativ unterscheidet, unabhängig von einem spezifischen Threshold.\n",
    "   Praktisches Beispiel: ROC-AUC = 0,9 → Bei zufälliger Auswahl eines Positiv- und eines Negativ-Beispiels wird der Klassifikator in 90 % der Fälle das Positive höher bewerten als das Negative.\n",
    "   Dein Modell kann 90 % der Zeit echte Klasse-1-Beispiele höher ranken als Klasse-0-Beispiele. Es unterscheidet sehr zuverlässig zwischen den Klassen. 0,5 wäre wie Zufall. Sehr gut bei stark unterschiedlichen Klassen\n",
    "5. F1-Score: harmonisches Mittel aus Precision und Recall. Der Score sagt voraus, wie gut das Modell gleichzeitig Precision und Recall erfüllt – also wie zuverlässig und wie vollständig\n",
    "   dein Modell die positive Klasse erkennt. Benötigt dazu 0/1 Werte der Minderheitsklasse. Sehr gut bei stark unterschiedlichen Klassen\n",
    "\n",
    "Grafische Bewertung und Ableitung\n",
    "1: ROC-Kurve (Receiver Operating Characteristic)\n",
    "Achsen:\n",
    "x-Achse: False Positive Rate (FPR) = FP / (FP + TN)\n",
    "y-Achse: True Positive Rate (TPR = Recall) = TP / (TP + FN)\n",
    "Interpretation:\n",
    "Zeigt die Leistung des Modells über alle möglichen Schwellenwerte\n",
    "ROC-AUC = Fläche unter der ROC-Kurve\n",
    "Werte: 0.5 = zufällig, 1 = perfekt\n",
    "Problem bei unbalancierten Daten:\n",
    "Wenn die negative Klasse sehr dominant ist, kann die FPR klein bleiben, selbst wenn das Modell viele Positive übersieht → ROC-AUC sieht „gut“ aus, obwohl das Modell die seltene Klasse schlecht erkennt.\n",
    "--> In diesem Fall vermutlich nicht so geeignet da die negative Klasse stark überweigt\n",
    "\n",
    "2: Precision-Recall-Kurve (PR-Kurve)\n",
    "Achsen:\n",
    "x-Achse: Recall (TP / (TP + FN))\n",
    "y-Achse: Precision (TP / (TP + FP))\n",
    "Interpretation:\n",
    "Fokus liegt nur auf der positiven (seltenen) Klasse\n",
    "Zeigt, wie präzise und vollständig die Vorhersagen der seltenen Klasse sind\n",
    "Average Precision = Fläche unter der PR-Kurve\n",
    "Vorteil bei unbalancierten Daten:\n",
    "PR-Kurve verschafft einen realistischen Blick auf die Modellleistung bei seltenen Ereignissen (z. B. Betrug, Krankheit).\n",
    "\n",
    "3. F1 score über Threshold\n",
    "Achsen:\n",
    "x-Achse: Threshold (Schwellwert), meist 0.0 → 1.0\n",
    "y-Achse: F1-Score\n",
    "Interpretation:\n",
    "Wie gut das Modell die positive Klasse (Klasse 1) erkennt – abhängig vom gewählten Threshold.\n",
    "Bei niedrigen Thresholds (z. B. 0.05):\n",
    "→ Modell sagt oft „positiv“ → hoher Recall, niedrige Precision → F1 kann steigen/fallen\n",
    "Bei hohen Thresholds (z. B. 0.9):\n",
    "→ Modell sagt kaum „positiv“ → hoher Precision, niedriger Recall → F1 sinkt fast immer\n",
    "Die Kurve hat meistens einen klaren Peak, der den besten Kompromiss zwischen Precision und Recall zeigt und somit den optimalen F1-Score liefert.\n",
    "0.7–1.0 = gut\n",
    "<0.3 = sehr schlecht\n",
    "\n",
    "Bei diesem Problem sit eine Bewertung auf average_precision am sinnvollsten und f1 zur Thresholdoptimierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de20f437-f8d5-46b9-ad05-53f182a147ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model_grid.best_estimator_ # Abrufen der besten Parametervariation aus dem fit und Übergabe an Pipeline\n",
    "xgb_model = best_model.named_steps[\"model\"] # abrufen des trainierten XGBClassifier\n",
    "plot_importance(xgb_model, max_num_features=20, importance_type='gain', height=0.6) # Berechnung und Darstellung der feature importance\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcf8708-2e30-4683-a0a8-02cf2c352153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gibt die 5 besten Ergebnisse der Parametervariation aus\n",
    "nr_best = 5\n",
    "\n",
    "mean_test_score = model_grid.cv_results_['mean_test_score']\n",
    "params = model_grid.cv_results_['params']\n",
    "\n",
    "best_scores_args = np.argsort(mean_test_score)[::-1][:nr_best]\n",
    "\n",
    "print(f'The {nr_best} best classification results\\n')\n",
    "for i in best_scores_args:\n",
    "    print(f'{100*mean_test_score[i]:.2f}  {params[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ca05ea-e154-4380-b597-785347c66b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrufen der besten Parametervariation aus dem fit und Übergabe an Pipeline\n",
    "model_grid = model_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7c79f4-9a8e-4025-9e46-4721a56503cb",
   "metadata": {},
   "source": [
    "## Precision-Recall Kurve vs. Threshold anzeigen, um evtl. besseren Threshold zu bestimmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94dc4d2-3641-4f60-ad63-befec086fd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Präzision: Von allen Fällen, die das Modell als positiv vorhergesagt hat, wie viele sind tatsächlich positiv?\n",
    "# Recall: Von allen tatsächlich positiven Fällen, wie viele erkennt das Modell korrekt?\n",
    "\n",
    "# Wahrscheinlichkeiten für Klasse 1\n",
    "y_pred_prob = model_grid.predict_proba(X_test)[:, 1] # gibt nur Wahrscheinlichkeit der positiven Klasse zurück (1)\n",
    "\n",
    "# Precision, Recall und Thresholds berechnen\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_prob)\n",
    "\n",
    "# thresholds hat N-1 Elemente, precision & recall N → deshalb [:-1] benutzen\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(thresholds, precision[:-1], label='Precision', color='blue') # threshold ist imemr eins kürzer als precision oder recall auf Grund der Brechnung von precision und recall n+1\n",
    "# letzten Wert von precision und recall abziehen für gleiche Länge, sonst Fehler\n",
    "plt.plot(thresholds, recall[:-1], label='Recall', color='red')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Precision / Recall')\n",
    "plt.title('Precision-Recall vs. Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# der Schnittpunkt ist der F1-Score mit bestem Verhältnis von Precision und Recall, hier lässt sich auch der zugehörige Threshold ablesen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9210a64d-a807-4bfb-85c0-011d33317905",
   "metadata": {},
   "source": [
    "## Precision-Recall Kurve anzeigen, um zu sehen wie gut das Modell ist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9f48d4-a74f-49c5-9867-3a4521693e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Präzision: Von allen Fällen, die das Modell als positiv vorhergesagt hat, wie viele sind tatsächlich positiv?\n",
    "# Recall: Von allen tatsächlich positiven Fällen, wie viele erkennt das Modell korrekt?\n",
    "# \"average_precision\" ist die Fläche unter der Kurve: 1 = perfektes Modell, das alle Positiven erkennt ohne False Positives, 0.5 = zufälliges Modell (nur grob bei stark unausgeglichenen Klassen).\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(recall, precision, marker='.', label='Precision-Recall-Kurve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall-Kurve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e50565-34a5-42ce-b713-63091a93b70d",
   "metadata": {},
   "source": [
    "## F1-Kurve, um Theshold für maximalen F1-Wert zu ermitteln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73abffb3-edb3-4856-8a32-b9ea25e25ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wahrscheinlichkeiten holen für die positive Klasse 1\n",
    "y_proba = model_grid.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Theshold von 0-1 testen\n",
    "thresholds = np.arange(0.0, 1.01, 0.01) # erzeugt eine Liste mit Werten von 0.0 - 1.0 in 0.01 Schritten\n",
    "f1_scores = [] # definiere leere Liste\n",
    "\n",
    "for t in thresholds: # geht jeden Wert in threshold durch\n",
    "    y_pred = (y_proba >= t).astype(int) # gibt für jeden threshold Wert True oder False zurück, je nachdem pb y_proba größer oder kleiner threshold\n",
    "    f1_scores.append(f1_score(y_test, y_pred)) # gibt für jedne threshold f1 Wert aus\n",
    "\n",
    "# Besten Threshold bestimmen\n",
    "best_index = np.argmax(f1_scores) # gibt den Maximalwert aus\n",
    "best_threshold = thresholds[best_index] # gibt dazu den dazugehörigen threshold aus\n",
    "best_f1 = f1_scores[best_index] # gibt den besten f1 score aus\n",
    "\n",
    "print(\"Bester Threshold:\", best_threshold)\n",
    "print(\"Bester F1-Score:\", best_f1)\n",
    "\n",
    "# f1-Verlauf als Grafik\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(thresholds, f1_scores)\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"F1-Score\")\n",
    "plt.title(\"F1-Score in Abhängigkeit vom Threshold\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6819cfcd-d819-490f-b77a-1fceb1281039",
   "metadata": {},
   "source": [
    "## Predictions/Vorhersagen ermitteln und ggf. Threshold anpassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3086c2a-df01-4a16-a1b9-692025b77e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wahrscheinlichkeiten für die positive Klasse\n",
    "probs_train = model_grid.predict_proba(X_train)[:, 1]\n",
    "probs_test = model_grid.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Eigenen Threshold anwenden, z.B. 0.3\n",
    "threshold = 0.5 # standard Threshold beträgt 0.5 bei sigmoid function\n",
    "y_train_predict = (probs_train >= threshold).astype(int) # wandelt Wahrscheinlichkeiten in 0 und 1 um mit definiertem threshold\n",
    "y_test_predict = (probs_test >= threshold).astype(int) # wandelt Wahrscheinlichkeiten in 0 und 1 um mit definiertem threshold\n",
    "\n",
    "# Test der Vorhersage mit den train-Daten\n",
    "#y_train_predict = random_search.predict(X_train) # wandelt Wahrscheinlichkeiten in 0 und 1 um mit Standard threshold von 0.5\n",
    "\n",
    "# Test der Vorhersage mit den test-Daten\n",
    "#y_test_predict = random_search.predict(X_test) # wandelt Wahrscheinlichkeiten in 0 und 1 um mit Standard threshold von 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590f1a9d-35b9-4dc8-bbf1-7a6b37b5a5af",
   "metadata": {},
   "source": [
    "## Sensitivity vs. Specificy (bei zuvor definiertem Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8272c4d3-4b8b-4844-8251-b3be8121557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity (Sensitivität) = Wie gut erkennt das Modell die Positiven (Betrug / Fälle / 1er)\n",
    "# Beispiel bei 79 %: Von allen tatsächlich positiven Fällen werden 79 % vom Modell richtig erkannt, 21 % übersieht das Modell und sind damit falsch negativ\n",
    "# Specificity (Spezifität) = Wie gut erkennt das Modell die Negativen (Nicht-Betrug / Nicht-Fälle / 0er)\n",
    "# Beispiel bei 82 %: Von allen tatsächlich negativen Fällen werden 82 % vom Modell richtig erkannt, 18 % werden vom Modell falsch positiv eingestuft\n",
    "\n",
    "# y_test = wahre Labels\n",
    "# y_test_predict = Vorhersagen (0/1)\n",
    "\n",
    "# berechnet die confusion Matrix und speichert die Werte true negative, false positive, false negative und true positive in Variablen\n",
    "cm = confusion_matrix(y_test, y_test_predict)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Berechnung der sensitivity und specificity\n",
    "sensitivity = tp / (tp + fn)   # Recall\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Speichern in einem DataFrame\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': ['Sensitivity (Recall)', 'Specificity'],\n",
    "    'Value': [sensitivity, specificity]\n",
    "})\n",
    "\n",
    "# Darstellung als Plot\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x='Metric', y='Value', data=metrics_df, palette='Blues')\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Sensitivität & Spezifität')\n",
    "for i, v in enumerate(metrics_df['Value']):\n",
    "    plt.text(i, v + 0.02, f\"{v:.2f}\", ha='center', fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf90a2e8-05d8-42ce-8509-54b388f3da02",
   "metadata": {},
   "source": [
    "## Confusion Matrix und Classification Report für Train-Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5084c5d-59a9-4d29-a4e6-a07de32d4868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen der Confusion Matrix für train-Daten\n",
    "cm = confusion_matrix(y_train, y_train_predict)\n",
    "plotted_matrix = ConfusionMatrixDisplay(confusion_matrix= cm)\n",
    "plotted_matrix.plot(cmap='Blues')\n",
    "y_train_scores = model_grid.predict_proba(X_train)[:, 1]\n",
    "#print(\"Precision score:\", precision_score(y_train, y_train_predict)) # precision score braucht 0/1 prediction\n",
    "#print(\"Recall score:\", recall_score(y_train, y_train_predict)) # recall score braucht 0/1 prediction\n",
    "#print(\"F1 score:\", f1_score(y_train, y_train_predict)) # f1 score braucht 0/1 prediction\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_train, y_train_scores)) # roc_auc_score braucht y_test_scores = random_search.predict_proba(X_train)[:,1], kann mit 0/1 nicht arbeiten. \n",
    "print(\"Average Precision score:\", average_precision_score(y_train, y_train_scores)) # average precision braucht y_test_scores = random_search.predict_proba(X_train)[:,1], kann mit 0/1 nicht arbeiten. \n",
    "#gibt Wert zwischne 0 und 1 aus, 1 sehr gute Präzision, 0 serh schlecht\n",
    "print(classification_report(y_train, y_train_predict)) # der classification report stellt precision, recall, f1-score und support für alle Klassen dar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c27bf7-54ec-4e6e-b0a1-15a44fb05e4d",
   "metadata": {},
   "source": [
    "## Confusion Matrix und Classification Report für Test-Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72fa55e-d95a-4f07-b90f-eab38d3d73f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen der Confusion Matrix für test-Daten\n",
    "cm = confusion_matrix(y_test, y_test_predict)\n",
    "plotted_matrix = ConfusionMatrixDisplay(confusion_matrix= cm)\n",
    "plotted_matrix.plot(cmap='Blues')\n",
    "y_test_scores = model_grid.predict_proba(X_test)[:, 1]\n",
    "#print(\"Precision score:\", precision_score(y_test, y_test_predict)) # precision score braucht 0/1 prediction\n",
    "#print(\"Recall score:\", recall_score(y_test, y_test_predict)) # recall score braucht 0/1 prediction\n",
    "#print(\"F1 score:\", f1_score(y_test, y_test_predict)) # f1 score braucht 0/1 prediction\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_test_scores)) # roc_auc_score braucht y_test_scores = random_search.predict_proba(X_train)[:,1], kann mit 0/1 nicht arbeiten. \n",
    "print(\"Average Precision score:\", average_precision_score(y_test, y_test_scores)) # average precision braucht y_test_scores = random_search.predict_proba(X_train)[:,1], kann mit 0/1 nicht arbeiten. \n",
    "#gibt Wert zwischne 0 und 1 aus, 1 sehr gute Präzision, 0 serh schlecht\n",
    "print(classification_report(y_test, y_test_predict)) # der classification report stellt precision, recall, f1-score und support für alle Klassen dar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13268719-608c-4c09-abff-786a5b5009b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gewichtung anpassen, wichtig bei stark ungleich verteilten Daten\n",
    "classes = np.unique(y_train)\n",
    "weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=classes,\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "class_weights = {cls: w for cls, w in zip(classes, weights)}\n",
    "print(\"Class Weights:\", class_weights)\n",
    "\n",
    "# Beispiel-Ausgabe bei 99:1: {0: 0.505, 1: 49.5}\n",
    "\n",
    "# Modell definieren\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(X_train.shape[1],)),\n",
    "\n",
    "    #layers.Dense(256),\n",
    "    #layers.LeakyReLU(),\n",
    "    #layers.BatchNormalization(),\n",
    "    #layers.Dropout(0.3),\n",
    "\n",
    "    layers.Dense(128),\n",
    "    layers.LeakyReLU(),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Dense(64),\n",
    "    layers.LeakyReLU(),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.2),\n",
    "\n",
    "    layers.Dense(32),\n",
    "    layers.LeakyReLU(),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.15),\n",
    "\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Neuronen hochstarten und dann reduzieren, immer die Hälfte\n",
    "# nicht mehr als 3 Zwischenschichten, da einfache Klassifikationsaufgabe\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005),\n",
    "    loss=\"binary_crossentropy\", # da binärer Zielwert 0 und 1\n",
    "    metrics=[\"precision\", \"recall\", \"AUC\"]   # Average Precision kommt im Evaluation-Teil\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# early stopping einbauen\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',       # worauf wir achten (oder 'loss' ohne Validation)\n",
    "    patience=3,               # wie viele Verschlechterungen erlaubt sind\n",
    "    mode='min',               # wir wollen den kleinsten Wert\n",
    "    restore_best_weights=True # beste Gewichte wiederherstellen\n",
    ")\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=2048,   # große Batch-Größe → schnell + stabil\n",
    "    validation_data=(X_test, y_test),\n",
    "    class_weight=class_weights,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# Auswertung\n",
    "y_pred_proba = model.predict(X_test).ravel()\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nClassification Report (Threshold=0.5):\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# average precision ausrechnen\n",
    "ap_score = average_precision_score(y_test, y_pred_proba)\n",
    "print(\"Average Precision (AP / PR-AUC):\", ap_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf9d565-745f-4324-ae48-f5cf55cb568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "\n",
    "# -------------------------\n",
    "# LOSS\n",
    "# -------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_dict[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history_dict[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.title(\"Loss-Verlauf\")\n",
    "plt.xlabel(\"Epoche\")\n",
    "plt.ylabel(\"Binary Crossentropy Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# -------------------------\n",
    "# PRECISION\n",
    "# -------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_dict[\"precision\"], label=\"Training Precision\")\n",
    "plt.plot(history_dict[\"val_precision\"], label=\"Validation Precision\")\n",
    "plt.title(\"Precision-Verlauf\")\n",
    "plt.xlabel(\"Epoche\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# -------------------------\n",
    "# RECALL\n",
    "# -------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_dict[\"recall\"], label=\"Training Recall\")\n",
    "plt.plot(history_dict[\"val_recall\"], label=\"Validation Recall\")\n",
    "plt.title(\"Recall-Verlauf\")\n",
    "plt.xlabel(\"Epoche\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# -------------------------\n",
    "# AUC\n",
    "# -------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_dict[\"AUC\"], label=\"Training AUC\")\n",
    "plt.plot(history_dict[\"val_AUC\"], label=\"Validation AUC\")\n",
    "plt.title(\"AUC-Verlauf\")\n",
    "plt.xlabel(\"Epoche\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bde2bb-6847-45fe-a0ac-8a5b5b69d10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = {\n",
    "    \"model\": [xgb.XGBClassifier()],\n",
    "    \"model__n_estimators\": [100], # Anzahl der Bäume\n",
    "    \"model__max_depth\": [3], # maximale Tiefe eines Baumes\n",
    "    \"model__scale_pos_weight\": [89], # Gewichtung der Minderheitsklasse, typisch Anzahl Negativwerte/Anzahl Positivwerte (98,897/1,103 = 89 in diesem Fall)\n",
    "    #\"model__reg_lambda\": [1] # Regularisation wie bei Ridge, Strafterm\n",
    "    #\"model__eval_metric\": [\"logloss\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dac3f1e-b20f-4c0b-90bc-e0660d64c1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = [{\n",
    "    \"model\": [RandomForestClassifier()],\n",
    "    \"model__n_estimators\": [100], # Anzahl der Bäume\n",
    "    \"model__max_depth\": [3], # maximale Tiefe eines Baumes\n",
    "    \"model__class_weight\": [\"balanced\"] # Klassengewichtung\n",
    "},\n",
    "\n",
    "{\n",
    "    \"model\": [GradientBoostingClassifier()],\n",
    "    \"model__n_estimators\": [100], # Anzahl der Bäume\n",
    "    \"model__max_depth\": [3] # maximale Tiefe eines Baumes\n",
    "},\n",
    "    \n",
    "    {\n",
    "    \"model\": [xgb.XGBClassifier()],\n",
    "    \"model__n_estimators\": [100], # Anzahl der Bäume\n",
    "    \"model__max_depth\": [3], # maximale Tiefe eines Baumes\n",
    "    \"model__scale_pos_weight\": [89], # Gewichtung der Minderheitsklasse, typisch Anzahl Negativwerte/Anzahl Positivwerte (98,897/1,103 in diesem Fall)\n",
    "    \"model__reg_lambda\": [1] # Regularisation wie bei Ridge, Strafterm\n",
    "    #\"model__eval_metric\": [\"logloss\"]\n",
    "}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5986c98c-d9c3-4432-9c6a-3cedc6967f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorbereitung der Daten mit Pipeline, eine Pipeline kann für sehr viele Modelle genutzt werden und arbeitet die verschiedenen Schritte ab\n",
    "pipe_log = Pipeline([\n",
    "    ('smote', BorderlineSMOTE(random_state=42)), # noch besser als SMOTE für unser Problem, erzeugt synthetische Samples die nahe an der KlassenGrenze liegen. WIrd automatisch nur auf Minderheitsklasse angewandt\n",
    "    #(\"smote\", SMOTE(random_state=42)), # vor dem Model aufrufen, Oversamping, erzeugt neue Datenpunke der Minderheitsklasse nur k-Neighbours, sodass gleich viele Daten von 0 und 1 vorhanden sind\n",
    "    # immer nur nach dem split nur auf Trainiingsdaten, WIrd automatisch nur auf Minderheitsklasse angewandt, danach gleiche Größe wie Mehrheitsklasse\n",
    "    # Benötigt zusätzlichen learn.pipeline import Pipeline für spezielle SMOTE pipeline\n",
    "    # Bestimmung der Funktion, ob Polynome Features eingeführt werden sollen (eher für kleine Datensätze)\n",
    "    #('preprocessing', PolynomialFeatures(2)), \n",
    "    # Bestimmung des Modells, penalty = \"l2\" ist standard und steht für Ridge-Regularisierung\n",
    "    # die Regularisierung führt einen Strafterm ein mit lambda, sodass es zu keinen Übergewichtungen von parametern kommt\n",
    "    # C (=1/lambda) bestimmt die Gesichtung des Strafterms, default ist hier 1.0\n",
    "    # max_iter bestimmt wie viele Iterationen zur Optimierung des Modells durchgeführt werden\n",
    "    (\"model\", LogisticRegression(max_iter=1000))\n",
    "    ])\n",
    "\n",
    "grid_search = {\n",
    "    #\"preprocessing__degree\": [2, 3],\n",
    "    \"model__penalty\": [\"l2\"], # Regularisierung, l1 für Lasso und l2 für Ridge\n",
    "    #\"model__solver\": [\"liblinear\", \"saga\"],\n",
    "    #\"model__l1_ratio\": [0.5],  # nötig für elasticnet\n",
    "    #\"model__class_weight\": [\"balanced\", {0:1, 1:5}], # gewichtet Klassen anders, jede 0 zählt normal mit Gewicht 1 und jede 1 zählt 5 mal so stark, ist eher trial and error\n",
    "    # balanced: automatische Anpassung der Gewichte an die Klassenhäufigkeit, jede Klasse bekommt ein Gewicht umgekehrt proportional zu ihrer Häufigkeit, setzt Gewicht für Fraud hoch und für Fraud nicht runter\n",
    "    #\"model__C\": [0.01, 0.1, 10]\n",
    "}\n",
    "\n",
    "# l1 für Lasso: Setzt manche Feature direkt auf 0 und entfernt sie somit, automatische Feature Selektion, starke Feature bleiben, schwache werden gelöscht\n",
    "# l2 für Ridge: Strafterm für Koeffizienten, große Koeffizienten werden mehr bestraft, alle Koeffizienten werden kleiner, keiner wird exakt 0, starke Features bleiben, schwache werden reduziert\n",
    "\n",
    "#erhält im Gegensatz zu kFold die die Klassenverteilung in jedem Fold, also proportional wie im gesamten Datensatz.(also wie bei stratify=y, nur für alle 5 cvs)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "model_grid = GridSearchCV(\n",
    "    pipe_log,\n",
    "    grid_search,\n",
    "    cv = cv, # macht 5 cross validation splits\n",
    "    scoring = \"average_precision\"\n",
    ")\n",
    "# scoring\n",
    "\n",
    "# Fit der Daten mit den Traindaten\n",
    "#pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6859e5e-42fe-4136-87ba-ec5c83587829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modellvalidierung mit statsmodel\n",
    "train_endog = y_train # Zielvariable (abhängige Variable)\n",
    "train_exog = sm.add_constant(X_train) # Erklärende Variablen (unabhängige Variable), sm.add_constant fügt Spalte mit nur Einsen hinzu für Intercept (β₀)\n",
    "\n",
    "test_endog = y_test # Zielvariable (abhängige Variable)\n",
    "test_exog = sm.add_constant(X_test) # Erklärende Variablen (unabhängige Variable), sm.add_constant fügt Spalte mit nur Einsen hinzu für Intercept (β₀)\n",
    "\n",
    "# Model Training\n",
    "logit_mod = sm.Logit(train_endog, train_exog)\n",
    "logit_res = logit_mod.fit()\n",
    "\n",
    "# Calculating probas\n",
    "logit_probabilities = logit_res.predict(test_exog)\n",
    "logit_predictions = pd.Series(logit_probabilities).apply(lambda x: 1 if (x > 0.5) else 0)\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(test_endog, logit_predictions)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(average_precision_score(test_endog, logit_predictions))\n",
    "\n",
    "print(logit_res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fdb771-3d85-4d29-a4b9-21982a928058",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
